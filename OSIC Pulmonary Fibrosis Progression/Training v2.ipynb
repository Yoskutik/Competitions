{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just another version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from awesome_progress_bar import ProgressBar\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from utils import LoggerCallback, DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_base_2.csv', index_col=0)\n",
    "\n",
    "def read(path):\n",
    "    fp = np.memmap(path, dtype='float32', mode='r', shape=(316, 316, 1))\n",
    "    \n",
    "    directory, filename = os.path.split(path)\n",
    "    n = int(filename.replace('.dat', ''))\n",
    "    n /= len(glob.glob(f'{directory}/*.dat'))\n",
    "    \n",
    "    patient = directory.split('\\\\')[-1]\n",
    "    \n",
    "    meta = [\n",
    "        n,\n",
    "        df.loc[patient, 'Sex'], \n",
    "        df.loc[patient, 'Age'], \n",
    "        df.loc[patient, 'SmokingStatus'],\n",
    "        df.loc[patient, 'FVC_0'],\n",
    "        df.loc[patient, 'Week'],\n",
    "    ]\n",
    "    \n",
    "    y = []\n",
    "    for x in [6, 8, 10, 12, 18]:\n",
    "        y.append(df.loc[patient, f'FVC_{x}'])\n",
    "        \n",
    "    return fp, meta, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('data\\\\train\\\\**/*.dcm')\n",
    "target_size = (316, 316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MySeparableConv2D(n_units):\n",
    "    def _(layer):\n",
    "        layer = SeparableConv2D(n_units, 3, activation='relu', activity_regularizer=l2(0.6))(layer)\n",
    "        layer = SeparableConv2D(n_units, 3, activation='relu', activity_regularizer=l2(0.6))(layer)\n",
    "        return MaxPool2D()(layer)\n",
    "    return _\n",
    "\n",
    "def create_embedder():\n",
    "    inp = Input([*target_size, 1])\n",
    "    inp2 = Input([6])\n",
    "\n",
    "    layer = MySeparableConv2D(32)(inp)\n",
    "    layer = MySeparableConv2D(64)(layer)\n",
    "    layer = MySeparableConv2D(128)(layer)\n",
    "    layer = MySeparableConv2D(256)(layer)\n",
    "    layer = GlobalAvgPool2D()(layer)\n",
    "    \n",
    "    layer2 = Dense(16, activation='relu')(inp2)\n",
    "\n",
    "    layer = Concatenate()([layer, layer2])\n",
    "    out = Dense(16)(layer)\n",
    "\n",
    "    return Model([inp, inp2], out)\n",
    "\n",
    "embedder = create_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Dense(24, activation='relu')(embedder.output)\n",
    "layer = Dense(5)(layer)\n",
    "model = Model(embedder.input, layer)\n",
    "model.compile('adam', 'mse', ['mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 30153\n",
      "Test dataset size: 3475\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "patients = os.listdir('data/train')\n",
    "np.random.shuffle(patients)\n",
    "\n",
    "train_size = int(np.round(len(patients) * (1 - test_size)))\n",
    "patients_train = patients[:train_size]\n",
    "patients_test = patients[train_size:]\n",
    "\n",
    "dat_train = []\n",
    "for x in patients_train:\n",
    "    dat_train.extend(glob.glob(f'data\\\\train\\\\{x}/*.dat'))\n",
    "dat_test = []\n",
    "for x in patients_test:\n",
    "    dat_test.extend(glob.glob(f'data\\\\train\\\\{x}/*.dat'))\n",
    "\n",
    "print(f'Train dataset size: {len(dat_train)}')\n",
    "print(f'Test dataset size: {len(dat_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "  941/941   |========================= 11:42 ==========================| 100.00%   mape:  66.89 - val_mape:  15.34\n",
      "Epoch 1:\n",
      "  941/941   |========================= 11:43 ==========================| 100.00%   mape:  51.09 - val_mape:  19.04\n",
      "Epoch 2:\n",
      "  941/941   |========================= 11:47 ==========================| 100.00%   mape:  48.99 - val_mape:  17.10\n",
      "Epoch 3:\n",
      "  941/941   |========================= 11:51 ==========================| 100.00%   mape:  47.62 - val_mape:  19.01\n",
      "Epoch 4:\n",
      "  941/941   |========================= 11:41 ==========================| 100.00%   mape:  46.20 - val_mape:  18.24\n",
      "Epoch 5:\n",
      "  941/941   |========================= 11:41 ==========================| 100.00%   mape:  44.79 - val_mape:  18.31\n",
      "Epoch 6:\n",
      "  941/941   |========================= 11:33 ==========================| 100.00%   mape:  43.43 - val_mape:  20.57\n",
      "Epoch 7:\n",
      "  941/941   |========================= 11:44 ==========================| 100.00%   mape:  42.38 - val_mape:  20.68\n",
      "Epoch 8:\n",
      "  941/941   |========================= 11:41 ==========================| 100.00%   mape:  41.32 - val_mape:  21.58\n",
      "Epoch 9:\n",
      "  941/941   |========================= 11:31 ==========================| 100.00%   mape:  40.40 - val_mape:  23.40\n",
      "Epoch 10:\n",
      "  941/941   |========================= 12:37 ==========================| 100.00%   mape:  39.63 - val_mape:  23.85\n",
      "Epoch 11:\n",
      "  941/941   |========================= 11:44 ==========================| 100.00%   mape:  39.04 - val_mape:  25.52\n",
      "Epoch 12:\n",
      "  941/941   |========================= 11:40 ==========================| 100.00%   mape:  38.52 - val_mape:  24.99\n",
      "Epoch 13:\n",
      "  941/941   |========================= 11:44 ==========================| 100.00%   mape:  38.25 - val_mape:  25.34\n",
      "Epoch 14:\n",
      "  941/941   |========================= 11:26 ==========================| 100.00%   mape:  37.92 - val_mape:  25.41\n",
      "Wall time: 2h 59min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = DataGenerator(dat_train, read)\n",
    "test = DataGenerator(dat_test, read)\n",
    "tf.get_logger().setLevel(\"ERROR\") \n",
    "\n",
    "history = model.fit(\n",
    "    train, \n",
    "    validation_data=test,\n",
    "    epochs=15,\n",
    "    callbacks=[LoggerCallback(len(train))],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_patient(directory):\n",
    "    imgs = []\n",
    "    meta = []\n",
    "    \n",
    "    dats = glob.glob(f'{directory}\\\\*.dat')\n",
    "    dats.sort(key=lambda d: int(d[:-4].split('\\\\')[-1]))\n",
    "    for dat in dats:\n",
    "        img, m, _ = read(dat)\n",
    "        imgs.append(img)\n",
    "        meta.append(m)\n",
    "    \n",
    "    imgs = np.array(imgs)\n",
    "    meta = np.array(meta)\n",
    "    \n",
    "    embedding = embedder.predict([imgs, meta])\n",
    "        \n",
    "    return np.hstack([\n",
    "        np.min(embedding, axis=0),\n",
    "        np.mean(embedding, axis=0),\n",
    "        np.max(embedding, axis=0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:   |=============================== 03:11 ===============================| 100.00% Complete\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "\n",
    "patients = os.listdir('data\\\\train')\n",
    "bar = ProgressBar(len(patients))\n",
    "for patient in patients:\n",
    "    bar.iter()\n",
    "    embeddings.append(embed_patient(f'data\\\\train\\\\{patient}'))\n",
    "    \n",
    "embeddings = pd.DataFrame(embeddings, index=patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('data/train.csv', index_col=0)\n",
    "new_df = new_df.drop(['Percent', 'Sex', 'Age', 'SmokingStatus'], axis=1)\n",
    "new_df = pd.merge(new_df, embeddings, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = new_df.loc[patients_train]\n",
    "df_test = new_df.loc[patients_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = df_train.loc[:, new_df.columns != 'FVC']\n",
    "X_test = df_test.loc[:, new_df.columns != 'FVC']\n",
    "y_train = df_train.FVC\n",
    "y_test = df_test.FVC\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584843014422967"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
