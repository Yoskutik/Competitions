{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from awesome_progress_bar import ProgressBar\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from utils import LoggerCallback, DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LoggerCallback` and `DataGenerator` placed in a separate module to increase code readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yeah. As I said, meta is: position of the scan, `SmokingStatus`, `Sex`, `Age`, FVCs measurement of the closest week to 0, and the closest week to 0. Output is FVCs measurements at weeks 6, 8, 10, 12 and 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_base.csv', index_col=0)\n",
    "\n",
    "def read(path):\n",
    "    fp = np.memmap(path, dtype='float32', mode='r', shape=(316, 316, 1))\n",
    "    \n",
    "    directory, filename = os.path.split(path)\n",
    "    n = int(filename.replace('.dat', ''))\n",
    "    n /= len(glob.glob(f'{directory}/*.dat'))\n",
    "    \n",
    "    patient = directory.split('\\\\')[-1]\n",
    "    \n",
    "    meta = [\n",
    "        n,\n",
    "        df.loc[patient, 'Sex'], \n",
    "        df.loc[patient, 'Age'], \n",
    "        df.loc[patient, 'SmokingStatus'],\n",
    "        df.loc[patient, 'FVC_0'],\n",
    "        df.loc[patient, 'Week'],\n",
    "    ]\n",
    "    \n",
    "    y = []\n",
    "    for x in [6, 8, 10, 12, 18]:\n",
    "        y.append(df.loc[patient, f'FVC_{x}'])\n",
    "        \n",
    "    return fp, meta, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('data\\\\train\\\\**/*.dcm')\n",
    "target_size = (316, 316)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the embedder. Seems like there's just not enough parameters. But actually R2 score on the test dataset is pretty high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MySeparableConv2D(n_units):\n",
    "    def _(layer):\n",
    "        layer = SeparableConv2D(n_units, 3, activation='relu', activity_regularizer=l2(0.6))(layer)\n",
    "        return MaxPool2D()(layer)\n",
    "    return _\n",
    "\n",
    "def create_embedder():\n",
    "    inp = Input([*target_size, 1])\n",
    "    inp2 = Input([6])\n",
    "\n",
    "    layer = MySeparableConv2D(16)(inp)\n",
    "    layer = MySeparableConv2D(16)(layer)\n",
    "    layer = MySeparableConv2D(32)(layer)\n",
    "    layer = MySeparableConv2D(32)(layer)\n",
    "    layer = GlobalAvgPool2D()(layer)\n",
    "\n",
    "    layer = Concatenate()([layer, inp2])\n",
    "    out = Dense(24)(layer)\n",
    "\n",
    "    return Model([inp, inp2], out)\n",
    "\n",
    "embedder = create_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Dense(5)(embedder.output)\n",
    "model = Model(embedder.input, layer)\n",
    "model.compile('adam', 'mse', ['mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 30265\n",
      "Test dataset size: 3363\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "dat_images = glob.glob('data\\\\train\\\\**/*.dat')\n",
    "\n",
    "train_size = int(np.round(len(dat_images) * (1 - test_size)))\n",
    "dat_train = dat_images[:train_size]\n",
    "dat_test = dat_images[train_size:]\n",
    "\n",
    "print(f'Train dataset size: {len(dat_train)}')\n",
    "print(f'Test dataset size: {len(dat_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "  944/945   |========================= 02:09 ==========================| 100.00%   mape: 116.44 - val_mape: 147.66\n",
      "Epoch 1:\n",
      "  944/945   |========================= 02:08 ==========================| 100.00%   mape: 106.46 - val_mape: 152.43\n",
      "Epoch 2:\n",
      "  944/945   |========================= 02:09 ==========================| 100.00%   mape: 109.38 - val_mape: 135.04\n",
      "Epoch 3:\n",
      "  944/945   |========================= 02:08 ==========================| 100.00%   mape: 108.14 - val_mape: 154.71\n",
      "Epoch 4:\n",
      "  944/945   |========================= 02:10 ==========================| 100.00%   mape: 109.21 - val_mape: 143.52\n",
      "Wall time: 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = DataGenerator(dat_train, read)\n",
    "test = DataGenerator(dat_test, read)\n",
    "tf.get_logger().setLevel(\"ERROR\") \n",
    "\n",
    "history = model.fit(\n",
    "    train, \n",
    "    validation_data=test,\n",
    "    epochs=5,\n",
    "    callbacks=[LoggerCallback(len(train))],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_patient(directory):\n",
    "    imgs = []\n",
    "    meta = []\n",
    "    \n",
    "    dats = glob.glob(f'{directory}\\\\*.dat')\n",
    "    dats.sort(key=lambda d: int(d[:-4].split('\\\\')[-1]))\n",
    "    for dat in dats:\n",
    "        img, m, _ = read(dat)\n",
    "        imgs.append(img)\n",
    "        meta.append(m)\n",
    "    \n",
    "    imgs = np.array(imgs)\n",
    "    meta = np.array(meta)\n",
    "    \n",
    "    embedding = embedder.predict([imgs, meta])\n",
    "        \n",
    "    return np.hstack([\n",
    "        np.min(embedding, axis=0),\n",
    "        np.max(embedding, axis=0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:   |=============================== 02:18 ===============================| 100.00% Complete\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "\n",
    "patients = os.listdir('data\\\\train')\n",
    "bar = ProgressBar(len(patients))\n",
    "for patient in patients:\n",
    "    bar.iter()\n",
    "    embeddings.append(embed_patient(f'data\\\\train\\\\{patient}'))\n",
    "    \n",
    "embeddings = pd.DataFrame(embeddings, index=patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('data/train.csv', index_col=0)\n",
    "new_df = new_df.drop(['Percent', 'Sex', 'Age', 'SmokingStatus'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(new_df, embeddings, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.loc[:, new_df.columns != 'FVC']\n",
    "y = new_df.FVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065728402301392"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. Pretty high. The embedder haven't seen scans of test dataset. Also the final regressor haven't seen them too. So, I guess that's really good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.save('data/embedder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
